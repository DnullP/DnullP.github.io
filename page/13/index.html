

<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta charset="UTF-8">
  <title> [ Dnull_P Welcome~ ]</title>
  
  <!-- stylesheets list from _config.yml -->
  
  <link rel="stylesheet" href="/css/Genso.css">
  
  <link rel="stylesheet" href="/css/layout/layout.css">
  
  <link rel="stylesheet" href="/css/layout/navigator.css">
  
  <link rel="stylesheet" href="/css/layout/page-container.css">
  
  <link rel="stylesheet" href="/css/layout/page-cover.css">
  
  <link rel="stylesheet" href="/css/layout/slidebar.css">
  
  <link rel="stylesheet" href="/css/index/index.css">
  
  <link rel="stylesheet" href="/css/index/recommend-card-container.css">
  
  <link rel="stylesheet" href="/css/index/card-container.css">
  
  <link rel="stylesheet" href="/css/index/card.css">
  
  <link rel="stylesheet" href="/css/post/post.css">
  
  <link rel="stylesheet" href="/css/post/idea.css">
  
  <link rel="stylesheet" href="/css/tool/color.css">
  
  
  <script>
    const urlList = ('https://s2.loli.net/2023/07/23/mivfcl7wqgVsYdP.jpg,https://s2.loli.net/2023/07/23/E3uyek7OVlJgtLT.jpg,https://s2.loli.net/2023/07/23/q9skN6cPAZ14fwH.png,https://s2.loli.net/2023/07/23/RedmkprBY81ZhaV.jpg,https://s2.loli.net/2023/07/23/pt1ArR7NqO8vMXl.png,https://s2.loli.net/2023/07/23/MZEW5UCFSBPiNvH.png,https://s2.loli.net/2023/07/23/8urpklSmq6xR5LF.jpg,https://s2.loli.net/2023/07/23/E6Os9tkrRP4FZ7f.jpg,https://s2.loli.net/2023/07/23/IPq4HsZCOfTMGxk.jpg,https://s2.loli.net/2023/07/23/sAhIbjyLeMBgfuw.jpg,https://s2.loli.net/2023/07/23/ipTsxHoDOawRrfM.png,https://s2.loli.net/2023/07/23/eTYKcWz7jb5mqyo.png,https://s2.loli.net/2023/07/23/lHLk3OMeY7qXnTP.jpg,https://s2.loli.net/2023/07/23/u9dvATztknGecmI.jpg,https://s2.loli.net/2023/07/23/calWvPZEbI9tG4o.png,https://s2.loli.net/2023/07/23/MLZr1j7hdDnIHGU.png,https://s2.loli.net/2023/07/23/PlqeV1XpgQrxI8u.jpg,https://s2.loli.net/2023/07/23/uWQXFEBh5iCcNJV.png,https://s2.loli.net/2023/07/23/xjcUksAMvHQVhim.jpg,https://s2.loli.net/2023/07/23/Bd46rfJ2HYhQGkM.jpg,https://s2.loli.net/2023/07/23/1BgtkI3Aw58qrGv.jpg,https://s2.loli.net/2023/07/23/z8naFUvWV7BfKud.jpg,https://s2.loli.net/2023/07/23/Xj4wlzuKTDQOmHh.png,https://s2.loli.net/2023/07/23/mKzLHqPkUWTivAu.png,https://s2.loli.net/2023/07/23/a36bWlVynziMrSU.jpg,https://s2.loli.net/2023/07/23/6ZNUeJAtDCRvWq8.jpg,https://s2.loli.net/2023/07/23/7nGYxgcyoi8aSIR.jpg,https://s2.loli.net/2023/07/23/EVeCvBAt1LOgJSU.jpg,https://s2.loli.net/2023/07/23/onE5MQBPGdzDROh.jpg,https://s2.loli.net/2023/07/23/316kgDancGthANM.jpg,https://s2.loli.net/2023/07/23/oeRXvLm5byqgazF.jpg,https://s2.loli.net/2023/07/23/HXj7NsSW5vyCoIn.jpg,https://s2.loli.net/2023/07/23/sqM2XznWeEol3f4.jpg,https://s2.loli.net/2023/07/23/xGAflC5roSOsJRz.jpg,https://s2.loli.net/2023/07/23/cF2oWANXImMREKx.jpg,https://s2.loli.net/2023/07/23/IqutSTML7EXRza3.jpg,https://s2.loli.net/2023/07/23/zYNG9XHIEfg4quh.png').split(',');
  </script>

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div class="background">
  

  <img src="https://s2.loli.net/2023/07/23/z8naFUvWV7BfKud.jpg" alt="">

  <div class="title-text animate__animated animate__bounce">
    <h1>This is
      <span class="name">
        Dnull_P
      </span>
    </h1>
    Welcome Hell !

  </div>
</div>

<div class="background-coverage">
  <!--Typed text-->
  <div class="background-coverage-text">
    <span id="background-coverage-text">
    </span>
  </div>
</div>

<div class="background-occupation">

</div>

  <div class="navigator">
  <div class="navi-buttom-container">
    
    
  <a href="/" class="navi-buttom">
    <div>
      Home
    </div>
  </a>
  
  
    
  <a href="/about" class="navi-buttom">
    <div>
      About
    </div>
  </a>
  
  
    
  <a href="/contact" class="navi-buttom">
    <div>
      Contact
    </div>
  </a>
  
  
    
    <div class="navi-dropdown">
      <div class="dropbtn">
        post
      </div>
      <div class="dropdown-content">
        
        <a href="/archives">
          Aarchives
        </a>
        
        <a href="/tags">
          Tags
        </a>
        
      </div>
    </div>
  </div>
  
  
</div>

  <div class="page-container">
    <div class="slidebar-warp">
  <div class="slidebar">
    <div class="panel">

      <div class="avatar">
        <img src="/pic/avatar.jpg" alt="">
      </div>

      <div class="info">
        <div class="subinfo-1">
          <div class="subinfo-1-left">
            <div class="subinfo-1-left-info">
              <div class="subinfo-1-left-info-inner">
                <div class="subinfo-1-left-info-front">
                  Post
                </div>
                <div class="subinfo-1-left-info-back random-color">
                  163
                </div>
              </div>
            </div>

            <div class="subinfo-1-left-info">
              <div class="subinfo-1-left-info-inner">
                <div class="subinfo-1-left-info-front">
                  Cate
                </div>
                <div class="subinfo-1-left-info-back random-color">
                  40
                </div>
              </div>
            </div>

            <div class="subinfo-1-left-info">
              <div class="subinfo-1-left-info-inner">
                <div class="subinfo-1-left-info-front">
                  Tag
                </div>
                <div class="subinfo-1-left-info-back random-color">
                  198
                </div>
              </div>
            </div>

          </div>

          <div class="subinfo-1-right">
            <div class="subinfo-1-right-inner">
              <div class="subinfo-1-right-front">
                This Month
              </div>
              <div class="subinfo-1-right-back random-color">
                9
              </div>
            </div>
          </div>
        </div>

        <div class="subinfo-2-wrap">
          <div class="subinfo-2">

            
            <div class="sociallink">
    <a href=https://github.com/DnullP>
      <img src="/svg/github.svg" alt="">
    </a>
</div>
            

          </div>
        </div>
      </div>

      <div class="more-opt">

      </div>

    </div>

    <div class="icon-warp">


      <button class="hide-slidebar-button">
        <img src="/svg/arrow-right-line.svg" id="slideBarArrow">
      </button>


    </div>
  </div>
</div>

    <div class="content">
      




<div class="card-container">

  <div class="card-list-title">
  <div class="card-list-title-text">
    <h2 class="divider">
      
      文章列表
      
    </h2>
  </div>
  
</div>

  
  
  

<div class="card" style="justify-content: left;">

  <div class="card-content">

    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        729字
      </div>
      <div class="card-info">
        阅读时间: 1 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <div style="transform: translateX(10px);">
      <a class="card-title" href="/2021/01/01/operating-system/CH1-Segmentation/">
        段式内存管理
      </a>
      <span class="card-abstract" style="transform: translateX(0px);">
        
# 段式内存管理

## 段

进程的虚拟内存空间是这样的(简化版):
| 代码段 | 堆 |空闲内存| 栈 |
| :---: | :---: | :---: |:---:|

其中的空闲内存不能占用物理内存空间, 所以我们考虑把进程的内存分成**段**(segment), 进程的内存将在物理内存中以段为单位分布

为了在段式分布的内存管理下完成内存翻译, 我们需要以下的信息:

- 段表: 参考之前说过的页表, 也是储存在内存中, 一个进程拥有一个的地址查找表, 但是记录的是进程分段的地址
- 段号: 说明段是哪一个段, 从而在段表中查询到该段的基地址
- 偏移量: 地址的段内偏移

整个过程也和分页查询很相似:

- 首先段式内存管理的内存地址如下:

  | 段号 | 偏移量 |
  | :---: | :---: |
- 然后CPU也有一个对应基址寄存器, 用来指向当前进程的段表, 我们用段号查询段表中的基址, 然后返回MMU
- 使用的得到的基址, 加上偏移量即可得到物理地址

---
段式内存管理系统已经被淘汰了, 在linux系统中的段基址都被设置为了0, 所以段只被用于进程的保护和权限控制, 而不再用于内存管理

为此, 段地址的会加上权限位, 搭配硬件的支持可以对不同的段进行不同的权限控制

段式内存也引发了**内存碎片**问题, 相关的说明和解决不在本章的讨论范围之内

      </span>
    </div>
  </div>

  <div class="card-img">
    <div class="img-container"></div>
  </div>

</div>



  
  
  
<div class="card" style="justify-content: right;">

  <div class="card-img">
    <div class="img-container"></div>
  </div>

  <div class="card-content">
    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        3.2k字
      </div>
      <div class="card-info">
        阅读时间: 3 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <a class="card-title" href="/2021/01/01/operating-system/CH1-directExecution/">
      直接运行程序
    </a>
    <span class="card-abstract">
      
这一部分主要分为两个主题：
- 如何限制进程对设备的访问更改，又能让进程一定程度上调用设备
- 如何在多个进程之间切换

### Restricted Operations

#### 引入权限分层
为了限制进程对内存或者其他设备的访问、更改等，OS引入了两个不同的模式：
- user mode
- kernel mode

在user mode中，程序只能执行有限的指令、访问有限的空间，如果程序试图访问一个非法的内存位置，那么OS将会中断程序

在kernel mode中，程序能够访问任何地方，执行任何指令

通过引入一个权限的分层，使得进程无法随意访问其他位置，那么现在的问题是如何让进程执行一些允许的内存访问与操作，比如我们的程序需要从硬盘读取数据，或者需要知道现在的内存剩余量为多少等等

#### 设置API
为了让用户模式的进程能够在OS的管理下访问内存和设备，OS为kernel mode制定了一系列的操作和面向user mode开放的API

比如我们之前就提到过的```exec```、```kill```等都属于系统调用（API of system）

用户模式下，通过把指定的参数写入规定的寄存器（register）中，然后使用 ```int```指令（一条汇编指令），搭配中断码```0x80```表示系统调用，OS会转入内核态，设备控制由进程交给OS，OS从寄存器中读取响应的参数，包括对应系统调用的代码，然后执行相应的系统调用，完成之后将返回值写入对应的寄存器，然后将context从栈中重新读取出

切换到内核态时，进程的context会被存入kernel stack中，类似于用户调用函数的原理一样，但是kernel stack相比user space stack需要在内核态才能使用

#### trap机制
系统的中断是通过trap机制实现的
来自硬件的错误、异常，来自进程的系统调用，来自用户输入的指令，都会向OS发送trap信号，接收到信号后如果没有特别设定中断处理程序，trap机制会根据信号的类型，依据trap table找到默认的中断处理程序的位置，并进行调用

trap table在OS启动时就已经读取完毕，一般在OS的源码内部就以及编写好了

### Switching Between Processes
上下文切换已经相对熟悉，不用做太多介绍，但是有一个问题是：
如果在一次中断中，正在进行上下文切换，此时另一个中断发生了，那么OS会如何操作呢？
这一部分将在并发（concurrency）中讲述，将关系到锁的一系列问题

此外，CPU在同一时间只能运行一个程序，当一般进程占用了CPU时，OS无法直接获得设备的操作权，所以OS一般有两种途径获得一个正在运行其他进程的CPU的操作权：
- 当进程触发了中断或者系统调用时，OS可以获得CPU操作权，并判断是否继续运行该进程
- 系统启动时会启动一个timer interrupter，每隔一定的时间就触发一次中断，强制将操作递给OS，并进行相应的管理

### summary

重点关键词：

- kernel mode和user mode
- system call和trap机制
- context Switching

### homework

课后要求估计上下文切换的时间和系统调用的时间

系统调用的时间比较好测量，在一次系统调用前后加上一个时间获取函数，然后相减即可，为提高精度还需要再减去两次连续使用的时间函数（去掉时间函数调用本身花耗的时间），并且提高测量次数

上线文切换相对比较麻烦，为了完成上下文切换的性能评估需要关注几点：

- 保证两个进程在同一个CPU上运行
- 排除时间函数本身的函数调用时间

为此我们需要写两个进程，一个运行无限循环，并在每次循环中放弃进程（通过`sched_yield()`方法），然后再写一个进程进行有限次数的循环，在每次循环中放弃进程，这样有限次循环花费的时间就大约是进程间上下文切换的总和，除以进程次数就是一轮切换的平均时间

代码如下：
固定次数部分：
```c
#define _GNU_SOURCE
#include &lt;assert.h&gt;
#include &lt;sched.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/time.h&gt;
#include &lt;unistd.h&gt;

int main() {
    int pid = getpid();
    printf(&#34;%d\n&#34;, pid);
    struct timeval tv;
    struct timeval tv_2;
    struct timezone tz;
    cpu_set_t cst;
    CPU_SET(0, &amp;cst);

    int t_0 = sched_setaffinity(getpid(), sizeof(cst), &amp;cst);

    double t_1 = gettimeofday(&amp;tv, &amp;tz);

    printf(&#34;%ld.%ld\n&#34;, tv.tv_sec, tv.tv_usec);

    int times = 0;

    t_1 = gettimeofday(&amp;tv, &amp;tz);

    for (int j = 1; j &lt;= 2000000; j++) {
        sched_yield();
    }
    t_1 = gettimeofday(&amp;tv_2, &amp;tz);
    printf(&#34;%ld.%ld\n&#34;, tv_2.tv_sec - tv.tv_sec, tv_2.tv_usec - tv.tv_usec);
}
```
首先`sched_setaffinity()`设置了一个进程只能运行的cpu集合，把该进程固定在一个CPU上
然后 ```gettimeofday()```获得当前的时间，固定循环记录上下文切换的总时间，但是上面的代码并没有考虑 ```gettimeofday()```本身函数调用花耗的时间

无限循环部分：
```c
#define _GNU_SOURCE
#include &lt;sched.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/time.h&gt;
#include &lt;unistd.h&gt;

int main() {
    int pid = getpid();
    printf(&#34;%d\n&#34;, pid);

    cpu_set_t cst;
    CPU_SET(0, &amp;cst);
    sched_setaffinity(getpid(), sizeof(cst), &amp;cst);

    while (1) {
        sched_yield();
    }
}
```
和上面类似，但是是无限循环，所以需要先启动这个进程

最后计算结果一轮上下文切换为1600ns左右，一次则为800ns左右，由于我使用的是虚拟机，所以和实际机器的上下文切换可能有所不同，另外，由于OS的进程调度机制，所以上下文切换的次数可能会比循环次数多许多，难以验证这样的计算结果




    </span>

  </div>

</div>



  
  
  

<div class="card" style="justify-content: left;">

  <div class="card-content">

    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        2.6k字
      </div>
      <div class="card-info">
        阅读时间: 2 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <div style="transform: translateX(10px);">
      <a class="card-title" href="/2021/01/01/operating-system/CH1-free-memory-management/">
        空闲内存的管理
      </a>
      <span class="card-abstract" style="transform: translateX(0px);">
        # 空闲内存的管理

关于这一段我还是相对熟悉的, 在做数据结构的大作业时选择了一个空闲链表的实现, 这一段的记录也会相对简洁

## 内存碎片

- 内部碎片(internal fragmentation): 内部碎片是由于最小分配的内存块大小大于实际分配大小所导致的内存碎片, 例如, 一个进程需要分配 10 个字节的内存, 但是内存管理器只能分配 16 个字节的内存块, 这样就会产生 6 个字节的内部碎片
- 外部碎片(external fragmentation): 当我们分配的内存空间不是最小分配单元时, 我们可以通过分割一个内存块来分配需要的内存空间, 而剩下的部分会形成一个新的空闲空间, 被称为外部碎片

空闲内存和碎片的合理分配可以让内存可以分配更大的内存块, 为此我们需要先在决定管理策略前, 实现基本的内存维护机制

## 空闲链表和已占用空间

对于一片内存中的空闲空间, 我们是通过空闲链表来管理的, 并且该链表是就在内存空间中**集成(embedded)** 的, 比如说我们有一片空闲的内存空间如下:
|size:1000|next:0x1000|data:...|size:1000|next:0x2000|data:...|
|:-:|:-:|:-:|:-:|:-:|:-:|
通过在空间头部加入两个字段, 来构成一个空闲链表
需要注意的是, 像这样连续的两空闲空间, 在产生时我们就应该将两块合并为一个, 以减少碎片的产生

同时, 对于一个已分配的空间也添加相应的字段来描述器大小和做验证:
|size:1000|magic:1234567|data:...|
|:-:|:-:|:-:|
我们可以向`free()`传递指向该占用块开头的指针, 知道该占用块的大小, 然后检测下一个字段的`magic`值是否为我们希望的值, 来判定这是一个完整的占用块(不能检测到一个大小就随意清楚后面的内存块)
需要注意的是, 我们在进程中调用`free()`传递的是虚拟内存的地址, 但是这个地址映射到物理内存上是不同的的地方

## 空闲链表的维护策略

当我们分配申请内存时, 需要先找到物理内存中足够大的空闲空间, 然后再将新分配的内存映射到这个区域之上, 但是我们希望在分配完了这个空间后能够产生尽量少的内存碎片, 所以就有了空闲链表的维护(分配)策略

需要注意的是, 我们所说的内存碎片也是物理内存中所产生的东西, 我们直接打交道的虚拟内存是不存在这种概念的, 这些策略都是OS来采用的方法, 只有OS才能和物理内存打交道

- 首次适应(first-fit): 首次适应是最简单的一种策略, 也是最容易实现的一种策略, 它的思想是从空闲链表的头部开始遍历, 找到第一个满足要求的空闲空间, 然后将其分配出去
- 最佳适应(best-fit): 最佳适应是从空闲链表中找到一个最小的空闲空间, 使得该空闲空间的大小刚好满足要求, 这样就能够减少内部碎片的产生
- 最坏适应(worst-fit): 最坏适应是从空闲链表中找到一个最大的空闲空间, 使得该空闲空间的大小刚好满足要求, 这样就能够减少外部碎片的产生
- 下一次适应(next-fit): 下一次适应是在首次适应的基础上进行的优化, 它的思想是从上一次分配的空闲空间的下一个空闲空间开始遍历, 这样能够使得内存的分配位置更加均匀

以上是四种简单的分配策略, 但是还有一些更加优秀, 但是也更加复杂的分配方式

在提及这些方式之前, 我们需要先明确, 我们上面讨论的情况是基于段式储存的, 一是段本身就已经是长度不固定的内存块了, 二是我们在段内部分配空间时也是按长度来取内存块的, 所以才会产生**外部碎片**
但是当我们采用分页式储存时, 我们的内存块大小都为固定的页大小, 我们分配内存的最小单位从字节变成了页, 所以我们的占用内存块和空闲内存块大小都是页大小(一般为4kb)的整数倍, 这样就不会产生外部碎片了——我们总能找到一块刚刚好大小的页来分配
所以针对外部碎片的这些策略都是基于段式储存或者直接映射物理内存的, 广泛采用的分页式储存不会产生外部碎片, 只有内部碎片(页大小固定, 大多数情况使用不完)

---

然后我们就能提及一个稍微复杂的针对非分页式的分配策略: **Segregated Free List(分离空闲链表)**

既然我们已经知道固定长度的分块不会产生外部碎片, 那么我们就尽量在不定长的分块中找到长度相同的区块, 然后把他们单独连成一个**隔离开的**链表, 这种部分的**类分页**方式就能一定程度上减少外部碎片的产生

其中的slab allocator就是这种方式的一种实现, 这个内存分配器将OS常用的那些对象单独创建一个空闲链表, 比如锁, 信号量, int等等, 同时减少了内部和外部碎片的产生

---
然后要介绍的是另一个强大的分配算法: **伙伴系统(buddy system)**:
我们对于一段大小为$2^n$的空闲空间, 将其**递归地**二分出一个最小的满足我们分配需求的空间, 比如我们现在有一块大小为$64kb$的空间, 需要分配一个$7kb$的空间:

- 我们可以通过二分分出一块$8kb$的空间, 此时产生了$1kb$的内部碎片, 此时的内存我们可以表示如下:

  |8kb|8kb|16kb|32kb|
  |:-:|:-:|:-:|:-:|
  |占用7kb|空闲8kb|空闲16kb|空闲32kb|

这个算法在分配方面只能分配$2$的幂次方大小的内存, 产生的内部碎片不确定和分页相比谁更优, 但是该算法在合并空闲内存(碎片)时更有优势:
- 我们释放了一个占用的空间后, 可以直接检测相邻的内存空间是否被占用, 然后可以直接将两个相同大小的内存空间合并
- 树形数组的原理可以和伙伴算法做一个比较参考, 两者都是大小为二进制数来分割区间的



      </span>
    </div>
  </div>

  <div class="card-img">
    <div class="img-container"></div>
  </div>

</div>



  
  
  
<div class="card" style="justify-content: right;">

  <div class="card-img">
    <div class="img-container"></div>
  </div>

  <div class="card-content">
    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        858字
      </div>
      <div class="card-info">
        阅读时间: 1 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <a class="card-title" href="/2021/01/01/operating-system/CH1-memoryTransflate/">
      地址翻译
    </a>
    <span class="card-abstract">
      这一章讲的比较浅显，我会结合CSAPP更详细地记录相关的过程原理

### 地址翻译是什么

地址翻译就是将我们已知的虚拟地址，通过MMU（Memory Management Unit）和CPU的协助转换为物理地址的过程

### 需要的专业名词

- 页（page）：内存中的一个连续的区域，是OS进行内存管理的最小单位
- 虚拟页（VP）：虚拟内存的一个连续的区域，对应于页
- 物理页（PP）：类比虚拟页
- 页表（page table）：一个表，储存在物理内存中，记录了虚拟页到物理页的映射关系
- 页表条目（PTE）：页表中的一项，记录了虚拟页到物理页的映射关系
- 基址寄存器（base register）：存储的进程起始地址

内存可以看作磁盘的一级缓存，我们用缓存机制来看待查询内存的过程：

- 查询内存中是否存在一个值，如果存在则直接读取，如果不存在则从磁盘读入

而我们通过虚拟地址查询内存的过程如下：

- 首先我们有一个虚拟地址, 这个地址属于一个进程, 而这个进程有自己基址寄存器对应的值, 而虚拟地址的字段如下:

| 页号 | 页内偏移 |
| --- | --- |

- 每一个进程都有自己对应的页表, 而基址寄存器指向了这个页表, 我们使用虚拟地址页号在页表中查询到对应的表项, 这个表项包含了虚拟页号对应的物理页号, 然后利用对应的物理页号和页内偏移就可以找到对应的物理地址

- 这个过程需要先访问一次内存查询一次PT, 再通过结果查询PP

---

书上将这一段内容时还没有引入内存分页, 所以只讲了简单的映射关系, 并没有涉及到页号和偏移这些, 但是也算是把分页系统下的地址翻译理了一下, 没有提到的细节可能会在之后的分页部分再说


    </span>

  </div>

</div>



  
  
  

<div class="card" style="justify-content: left;">

  <div class="card-content">

    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        4k字
      </div>
      <div class="card-info">
        阅读时间: 4 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <div style="transform: translateX(10px);">
      <a class="card-title" href="/2021/01/01/operating-system/CH1-paging/">
        分页
      </a>
      <span class="card-abstract" style="transform: translateX(0px);">
        
# 分页

之前我们已经对分页有了一个大概的概念, 现在我们详细描述一下分页过程以及中间产生的一些问题:

## 分页储存下的地址翻译

我们在地址翻译的相关内容中已经描述了分页时的地址翻译过程:

- 查询页表, 获取物理地址
- 查询物理地址, 获取数据

其中, 页表是储存在物理内存中由操作系统管理的 (书中说操作系统能够对自身进行虚拟化, 所以页表实际上也要经过从虚拟地址到物理地址的转换), 所以这个地方需要查询两次物理内存才能的到最后要得到的数据

这个过程会花耗大量的时间, 所以OS引入了一个硬件来加速这个过程, 我们称之为TLB(Translation Lookaside Buffer), 也就是翻译旁路缓冲器, 其本质就是一个缓存机制而已, 通过将频繁查询的PTE储存在一个高速缓存中, 供MMU快速查询数据的物理地址

## PTE的结构

我们引用来自文章[Page Table Entries in Page Table](https://www.geeksforgeeks.org/page-table-entries-in-page-table/)的图片:
![](https://media.geeksforgeeks.org/wp-content/uploads/Capture-24.png)

PTE的结构包括以上几个部分:

- Frame Number: 用于存储数据的物理页的页号

**tips**: 我们称物理页(Physical Page)又叫物理帧(Physical Frame)

- present/absent: 用于标记该页是否在内存中, 如果为0, 则表示该页不在内存中, 需要从磁盘中读取, MMU会产生一个缺页错误, 然后调用OS进行磁盘的读取; 如果为1, 则表示该页在内存中, 可以直接访问
- protection: 用于标记该页的访问权限, 包括: 可读, 可写, 可执行等
- reference: 用于标记该页在一个时钟周期内是否被访问过, 一般用于缓存机制的实现: 当内存满时, 如果此位为0, 说明该页属于不常用页, 所以被新页替换, 此外的替换算法还有许多, 如果有需要的话会在缓存部分再做说明
- Caching: 用于标记该页是否被缓存, 部分的数据并不需要缓存, 而是必须实时更新, 这一位用于取消对数据的缓存(缓存是指相对内存更高一级的缓存, 一般位于CPU内)
- Dirty(modified): 这一位用于标记内存数据是否被修改过, 修改过的数据需要写回磁盘中, 仅此而已

## 时间局部性和空间局部性

本来这部分在CSAPP中已经有了详细的描述, 但是这一部分中我没有做相应的笔记, 所以在此对两类局部性做一个记录

- 空间局部性: 假如我们有一个数组, 我们循环访问该数组的元素, 此时我们访问的元素是分布在同一个内存页上的(同一个虚拟页和物理页), 那么我们已经访问了一个page的首个元素后, 后面的一部分元素的PTE就已经缓存到了TLB中, 由此加速了地址查询, 同时如果发生了缓存不命中, 后面的元素也不会再发生缓存不命中的情况, 这样就加速了对数组元素的访问

- 时间局部性: 一个已经被缓存的元素, 接下来可能被多次访问, 我们则称为时间局部性, 频繁访问的数据更容易被缓存, 从而加速访问

## 处理TLB missing

处理这种缓存不命中, 有两种方法: 通过硬件或软件来实现

- 硬件实现: 比较传统的方式, 需要硬件设备的支持
- 软件实现: 一般来说被现代OS所采用, 此时硬件(TLB所在的硬件)在发生缺页异常时, 只会引起一个中断, 然后由OS来处理这个中断, 即执行一个缺页处理程序
  这个程序在一个未被映射的物理内存中, 同时TLB中始终位置其位置(不会因为缓存替换)

## 进程切换时的TLB处理

TLB是页表的缓存, 而每个进程的页表都是单独储存的, 所以上下文切换时需要维护TLB的正确性

### 简单的方式

简单的方式就是直接清除TLB, 这样在切换进程后重新构建TLB表, 可以保证TLB的正确性, 但是这样会导致TLB的命中率下降, 从而导致性能下降, 所以常见的OS通常采用下面这种方式

### ASID

ASID(Adress Space IDentifier)是一个硬件支持的特性, 用于区分不同进程的页表, 我们为每一个TLB中的条目添加一个`ASID`字段, 用于标记该条目所属的进程, 然后为每个进程再单独维护一个`ASID`的属性, 然后进行TLB查询时就可以区别不同进程使用的TLB条目了

---

处理了时间上的缺点后, 页表同样存在空间上的缺点: 页表占用空间过大
我们只需要为进程中使用的虚拟地址分配物理地址, 但是没有使用的虚拟地址仍然需要一个页表来维护其映射, 否则就会造成内存地址不连续, 影响指针等地址相关的操作

## 多级页表

多级页表可以看作一棵树, 我们把页表分成多层, 用类似线段树的方式来储存, 然后参考**懒标记**的原理, 只有我们确实为某个虚拟地址分配了物理地址后, 才会在相应的路径中分配页表

而没有实际分配的虚拟地址只会记录到有分配的地址为止, 我们可以参考下面这张图来理解多级页表:

下面是来自CSDN的多级页表示意图:
  
![](https://img-blog.csdn.net/20180111231317615?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZm9yRHJlYW1ZdWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

其中用箭头连接的页表项才是有对应物理页映射的, 中间的空的区域就没有下一级的页表, 这么一来就节约了未分配空间的页表储存(这些页表概念上存在, 但是并没有实际储存)

## 倒页表(Inverted Page Table)

倒页表又是一种特殊的页表, 其通过虚拟地址管理分配整个物理地址空间, 只有唯一的一个页表用于管理全部内存
程序使用的内存的位置通过一个hash表来储存

## 内存交换

一般来说, 我们分配给进程的内存地址空间(虚拟地址空间)要大于实际可以分配的物理内存, 这是为了进程可以更灵敏自由的使用需要的内存, 但是这也就导致我们的内存空间存在满载的情况

这个时候我们需要找到一部分未被使用的数据, 将其写入磁盘中的一块特殊的预留区域 **交换区(swap area)**, 然后将其从物理内存中**驱逐(evict)**
被驱逐到磁盘中的数据也有自己的虚拟地址, 储存在页表(或者TLB)之中, 但是其指向的将不是物理内存, 而是对应的**磁盘地址**, 这样我们就可以在需要的时候将其从磁盘中读取到内存中, 从而实现内存的交换

这一部分位于磁盘中的内存区域我们称为**虚拟内存(virtual memory)**, 内存交换机制可以看作位于内存和磁盘之间的一个缓存机制, 可以采用以下较为经典的内存交换策略:

- 先进先出(FIFO)
  找到最早进入内存的数据作为驱逐对象. 这个方案表现比较落后, 不多考虑
- 最久未使用(Least Recently Used, LRU)
  最少使用(Least Frequently Used, LFU)
  找到最久未使用或者最少使用的数据作为驱逐对象. 这两个方案是目前最常用的方案, 但是存在一个问题: 寻找这么一个数据需要遍历整个内存, 这样的开销是非常大的, 所以我们提出了下面一种优化方案
- 时钟算法LRU
  我们通过一个硬件时钟来周期性的给内存中的数据打上标记, 如果一个数据被使用读取就去掉它的标记, 如果我们需要找到一个用来驱逐的数据, 只需找一个有标记的数据即可, 这说明这个数据被读取到内存后有一段时间没有被读取过了

以上算法都无法达到最优的优化, 内存的交换策略还有可以优化的空间

### 内存交换的细节和小优化

#### 水位线(watermark)

我们对于一个内存的**满**的概念有所不同, 我们使用一个水位线来标记内存的使用情况, 当内存占用高于一个水位线(阈值), 则开始进行驱逐操作, 保持一个适量的可用空间作为缓冲

而当内存低于某个水位线时, 我们可以从磁盘(虚拟内存)中选取一些数据到内存中, 从而减少后续可能需要的内存交换所花耗的时间(总所周知IO操作是非常耗时的)

#### 抖动(thrashing)

由于某些原因, 我们的内存交换策略可能会导致内存中的数据频繁的被驱逐和读取, 这样的现象我们称为thrashing
一种简单的导致thrashing的情况是, 内存占用到达上限, 而进程还在不断地增加用量, 我们就只能驱逐, 然后存入新数据, 然后驱逐...进而产生大量的IO消费

Linux中解决这种问题的一个方案是直接杀死部分进程, 防止thrashing的发生

#### 一次读入多个连续页面

由于程序具有局部性, 我们可以一次性读入多个连续的页面, 可以减少IO的读取操作


      </span>
    </div>
  </div>

  <div class="card-img">
    <div class="img-container"></div>
  </div>

</div>



  
  
  
<div class="card" style="justify-content: right;">

  <div class="card-img">
    <div class="img-container"></div>
  </div>

  <div class="card-content">
    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        5.6k字
      </div>
      <div class="card-info">
        阅读时间: 5 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <a class="card-title" href="/2021/01/01/operating-system/CH1-processAPI/">
      进程的API
    </a>
    <span class="card-abstract">
      
这一段被作为间章，介绍了几种UNIX系统使用的进程相关的系统调用

---

### fork()

首先我们有一段使用 ```fork()```函数的代码：

```c
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
int main(int argc, char *argv[])
{
    printf(&#34;hello world (pid:%d)\n&#34;, (int)getpid());
    int rc = fork();
    if (rc &lt; 0)
    {
        // fork failed
        fprintf(stderr, &#34;fork failed\n&#34;);
        exit(1);
    }
    else if (rc == 0)
    {
        // child (new process)
        printf(&#34;hello, I am child (pid:%d)\n&#34;, (int)getpid());
    }
    else
    {
        // parent goes down this path (main)ss
        printf(&#34;hello, I am parent of %d (pid:%d)\n&#34;,
               rc, (int)getpid());
    }
    return 0;
}
```
- PID
  这是对进程的标识符，对应当前OS中唯一的一个进程

```fork()```函数会创建一个和当前进程**完全一样**的进程，完全一样包括了两者的context也完全一致，也就是说，当父进程运行到第7行执行了 ``` fork()```时，新创建的子进程也运行到相同的位置，刚刚执行完相同的函数

但是有一点区别，父进程得到的 ```fork()```的返回值是子进程的PID，而子进程在相同地方的到的返回值是**0**，所以程序可以由此设置条件判断，从而使子进程和父进程产生不一样的行为

此外如果多运行几次我们就会发现，子进程和父进程的输出先后是随机的，因为两者分开后就各自运行了，双方谁先运行到输出语句是不确定的，详细的细节我们会在并发（concurrency）的章节和多线程一起讨论

我们可以通过使用下面的 ```wait()```来使输出的顺序固定
### wait()
这个系统调用可以让程序等待一个进程结束，再进行下面的操作，根据传递的参数不同，等待的对象也不同

下面是一段使用了 ```wait()```的代码：

```c
 #include &lt;stdio.h&gt;
 #include &lt;stdlib.h&gt;
 #include &lt;unistd.h&gt;
 #include &lt;sys/wait.h&gt;
int main(int argc, char *argv[])
{
    printf(&#34;hello world (pid:%d)\n&#34;, (int)getpid());
    int rc = fork();
    if (rc &lt; 0)
    { // fork failed; exit
        fprintf(stderr, &#34;fork failed\n&#34;);
        exit(1);
    }
    else if (rc == 0)
    { // child (new process)
        printf(&#34;hello, I am child (pid:%d)\n&#34;, (int)getpid());
    }
    else
    { // parent goes down this path (main)
        int rc_wait = wait(NULL);
        printf(&#34;hello, I am parent of %d (rc_wait:%d) (pid:%d)\n&#34;,
               rc, rc_wait, (int)getpid());
    }
    return 0;
}
 ```
上面的代码让父进程在输出之前暂停，然后等到子进程结束后才继续运行

### exec()

这个调用可以让程序启动不同的进程，作为当前进程继续运行：
```c
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/wait.h&gt;

int main(int argc, char *argv[])
{
    printf(&#34;hello world (pid:%d)\n&#34;, (int)getpid());
    int rc = fork();
    if (rc &lt; 0)
    { // fork failed; exit
        fprintf(stderr, &#34;fork failed\n&#34;);
        exit(1);
    }
    else if (rc == 0)
    { // child (new process)
        printf(&#34;hello, I am child (pid:%d)\n&#34;, (int)getpid());
        char *myargs[3];
        myargs[0] = strdup(&#34;wc&#34;);   // program: &#34;wc&#34; (word count)
        myargs[1] = strdup(&#34;p3.c&#34;); // argument: file to count
        myargs[2] = NULL;           // marks end of array
        execvp(myargs[0], myargs);  // runs word count
        printf(&#34;this shouldn’t print out&#34;);
    }
    else
    { // parent goes down this path (main)
        int rc_wait = wait(NULL);
        printf(&#34;hello, I am parent of %d (rc_wait:%d) (pid:%d)\n&#34;,
               rc, rc_wait, (int)getpid());
    }
    return 0;
}
```

输出结果如下：
```
hello world (pid:49490)
hello, I am child (pid:49491)
 32 119 970 p3.c
hello, I am parent of 49491 (rc_wait:49491) (pid:49490)
```

这个程序把上面说的三种调用全部使用了，首先创建一个拷贝的子进程然后在子进程中启动了 ```wc```指令，并且让父进程调用 ```wait()```等待子进程结束

### 上面的API有何用？

当我们需要创建一个进程时，使用 ```fork()```和 ```exec()```组合是相当有用的，打开shell输入指令，shell会先拷贝一份当前进程，然后设置一系列的执行程序需要的环境，然后才 ```exec()```启动接下来的程序

比如下面一段代码：
```c
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;string.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/wait.h&gt;
int main(int argc, char *argv[])
{
    int rc = fork();
    if (rc &lt; 0)
    {
        // fork failed
        fprintf(stderr, &#34;fork failed\n&#34;);
        exit(1);
    }
    else if (rc == 0)
    {
        // child: redirect standard output to a file
        close(STDOUT_FILENO);
        open(&#34;./p4.output&#34;, O_CREAT | O_WRONLY | O_TRUNC, S_IRWXU);

        // now exec &#34;wc&#34;...
        char *myargs[3];
        myargs[0] = strdup(&#34;wc&#34;);   // program: wc (word count)
        myargs[1] = strdup(&#34;p4.c&#34;); // arg: file to count
        myargs[2] = NULL;           // mark end of array
        execvp(myargs[0], myargs);  // runs word count
    }
    else
    {
        // parent goes down this path (main)
        int rc_wait = wait(NULL);
    }
    return 0;
}
```
程序在开始新的 ```execvp()```程序运行之前，会先关闭当前的屏幕输出，然后打开一个文件
```open()```函数的第二个参数我们称为打开标志（open flag），这里的三个参数表示：
- O_CREAT
  不存在文件则创建
- O_WRONLY
  以只写的方式打开文件
- O_TRUNC
  打开文件后若可写，则清空文件内容

### 进程控制和用户
用户通过 ```kill```指令向一个进程发送**信号（signal）** 来杀死一个进程，也可以通过组合键 ```ctrl C```、```ctrl Z```等方式发送信号
发送信号可以说是用户和其他进程直接控制进程的方式，同时，为了防止任何用户都可以发送信号来随意控制进程，OS还有着为不同的用户管理进程分配资源的工作，不同的用户只能控制自己创建的进程

### 有用的小工具

- ps
  显示某些进程
- top
  显示系统进程，并显示其对资源的占用
- kill 和 killall
  杀死进程，不说了

### homework

记几个值得记录的问题

1. 如何不使用 ```wait()```调用来保证子进程和父进程的执行顺序？
   使用进程间信号量，包括SYSTEM V和POSIX的信号量
2. exec函数族为啥有一堆函数和指令？
   首先看一下六种指令的接口：
   ```c
   int execl(const char *path, const char *arg, ...);
   int execlp(const char *file, const char *arg, ...);
   int execle(const char *path, const char *arg,
   ..., char * const envp[]);
   int execv(const char *path, char *const argv[]);
   int execvp(const char *file, char *const argv[]);
   int execvpe(const char *file, char *const argv[],
   char *const envp[]);
   ```
   我们可以先按照 ```l```和 ```v```两类分，```l```使用的是若干个参数的指针，一个参数代表一个输入，而 ```v```传递了一个数组，数组内包含要传递的参数
   然后最后的 ```e```表示最后一个参数传入一个环境变量的参数
   中间的 ```p```则代表了寻找可执行程序的方式不同，对于 ```p```类型来说，如果可执行程序不带有斜杠```/```，则从shell中查找可执行程序

3. 写一个程序，用```pipe()```连接两个进程
   除了使用进程间信号量，使用pipe也可以控制两个进程的执行先后，本质还是进程间通信，pipe本质是OS创建一个指针变量 ```file pipe[2]```这两个文件指针一个指向写进程，一个指向读进程，中间用一个缓冲区连接，通过向指针指向的位置读写实现进程通信




    </span>

  </div>

</div>



  
  
  

<div class="card" style="justify-content: left;">

  <div class="card-content">

    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        3.1k字
      </div>
      <div class="card-info">
        阅读时间: 3 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <div style="transform: translateX(10px);">
      <a class="card-title" href="/2021/01/01/operating-system/CH1-processes/">
        进程
      </a>
      <span class="card-abstract" style="transform: translateX(0px);">
        
第一章第一节是进程相关内容，我们在CSAPP中已有过些许了解
另外本文是我学习的记录，具有局部性，其中的描述并不一定正确完整，只是跟随书的思路把关键点记录下来

## 进程
进程就是一个运行的程序，而现在我们希望计算机能够同时运行多个程序，我们希望计算机在运行浏览器时播放音乐等等，所以我们需要之前提及的CPU虚拟化技术

也就是说，我们在进程之间不停地切换，来制造程序同时运行的假象，这样做当然会降低每个进程的平均速度，产生更大的性能消耗
为了实现CPU虚拟化，我们需要从底层机制和高级机制两个方面来考虑：
- 底层机制包括上下文切换（context switching），通过这种机制来实现进程的切换，并且保证切换回原进程后能够以之前的状态继续运行
- 高级机制是OS对底层机制的智能操作，举个例子：OS需要一种策略来判断一个时刻执行哪个进程才是更高效的选择，通过记录进程的历史信息、进程类型等信息来对进程进行评估，并决定切换到哪个进程

### 进程的组成

一个进程可以由以下内容组成：

- 内存
  内存中储存了程序的指令、数据
- 寄存器
  寄存器是进程直接操作的对象，包括PC寄存器，栈寄存器等
- I/O设备
  进程需要记录下I/O设备中读取的文件的信息等，便于修改和保存、拷贝等

### 进程相关的API

- create
  创建一个进程
- destroy
  杀死一个进程
- wait
  等待一个进程结束
- miscellaneous control
  包括暂停、继续之类的各种控制进程的方式
- status
  获取进程的相关信息

### 创建一个进程的更多细节
- 从I/O设备中读取指令和静态数据，存入内存
- 为程序分配栈空间，压入相关的数据、参数
- 建立和I/O设备的交互工作

完成准备后程序进入 ```main()```函数开始进程

### 进程状态

```plantuml
@startuml
hide empty description
state Running
state Ready
state Blocked
Running -&gt; Ready : Descheduled
Ready -&gt; Running : Scheduled
Blocked -&gt; Ready : I/O done
Running --&gt; Blocked : I/O initiate
@enduml
```

- Running
  此时进程正在进行，占用内存、寄存器、CPU等资源
- Ready
  此时进程处于准备完成状态，指令和数据已经存入内存中，等待OS开始执行
- Blocked
  阻塞状态，此时程序由于某些操作需要使用I/O设备，所以停止运行，并等待I/O设备运行完成，然后进入Ready状态

进入Ready状态的进程会排队等待Running的进程完成或者进入Blocked状态

### 进程相关数据结构

OS需要保存足够的进程信息，以便查找到指定的进程进行操作，不同的OS会使用不同的数据结构储存这些信息，我们称该数据结构为**进程控制块（process control block）**，下面是xv6系统的进程信息的数据结构：

```c
// the registers xv6 will save and restore
// to stop and subsequently restart a process
struct context {
int eip;
int esp;
int ebx;
int ecx;
int edx;
int esi;
int edi;
int ebp;
};
// the different states a process can be in
enum proc_state { UNUSED, EMBRYO, SLEEPING,
RUNNABLE, RUNNING, ZOMBIE };
// the information xv6 tracks about each process
// including its register context and state
struct proc {
char *mem; // Start of process memory
uint sz; // Size of process memory
char *kstack; // Bottom of kernel stack
// for this process
enum proc_state state; // Process state
int pid; // Process ID
struct proc *parent; // Parent process
void *chan; // If !zero, sleeping on chan
int killed; // If !zero, has been killed
struct file *ofile[NOFILE]; // Open files
struct inode *cwd; // Current directory
struct context context; // Switch here to run process
struct trapframe *tf; // Trap frame for the
// current interrupt
};
```

我们可以看见context结构中储存了当前的寄存器的值，自然也包括了PC寄存器和栈寄存器等，OS把context保存着，然后可以停止进程的运行，并使其阻塞，然后运行其他进程

在需要的时候，OS将context的值重新写入寄存器中，这就是我们说的上下文切换

除此之外，```proc```中还包括了进程状态、内存大小、pid等信息，代码中有详细的每个变量的说明

一个进程除了之前说过的三种状态外，还可能处于initial状态，此时进程刚刚创建，还没有从I/O设备读取数据指令
还有final状态，此时进程已经完成，但是OS还没有将其清理（从内存中删除），UNIX-based OS将其称为僵尸进程（zombie process），僵尸进程一般用于在一个程序结束后检查其返回码（return code），来确定其完成状态

- 在一个进程结束前，它会最后调用一次 ```wait()```调用，等待其子进程的结束

---

## HOMEWORK
课后的工作中给了一个模拟进程指令的py程序，通过输入参数来模拟CPU处理多个进程的上下文切换，其中最主要的对比任务是，当一个进程完成I/O设备工作后，是立刻切换回这个进程继续工作，还是按照顺序优先完成Running的工作更快

通过对比和查找资料我们可以得知，现在的CPU计算速度越来越快，进程更加趋向于I/O密集型进程，也就是说进程运行中的绝大部分时间是消耗在I/O运作上，所以我们应该偏向于在一个进程完成I/O操作后立刻切换到其进行CPU计算，这样能有更大的概率让进程都处于I/O处理的阻塞状态，提高I/O设备利用率

      </span>
    </div>
  </div>

  <div class="card-img">
    <div class="img-container"></div>
  </div>

</div>



  
  
  
<div class="card" style="justify-content: right;">

  <div class="card-img">
    <div class="img-container"></div>
  </div>

  <div class="card-content">
    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        3.4k字
      </div>
      <div class="card-info">
        阅读时间: 3 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <a class="card-title" href="/2021/01/01/operating-system/CH1-proportionalShare/">
      分比例调度
    </a>
    <span class="card-abstract">
      
# 分比例调度
分比例调度就是每个进程都获得一个比例，所占比例越大的进程越容易被调度运行

## Lottery Scheduling（彩票调度）
Lottery调度的关键在于票据（tickets）,每个进程被分配了一定数量的票据，然后我们利用随机数，随机抽取一张票，拥有这个ticket的进程就能被调度运行，按照概率论（probability theory）的理论，当随机次数足够多时，每个进程被调度的概率接近于其tickets数量所占的比例

具体实现方式如下：
- 首先我们用一个链表，每个节点上储存的是每个进程的进程信息，其中包括了进程的tickets数量
- 然后我们利用生成器随机生成一个票数以内的数字
- 接着我们遍历链表，将每个进程的tickets数量加起来，当加起来的数量大于随机生成的数字时，就确定了这个进程被调度运行

一般tickets数量比较大的进程被排在链表前面，这样可以减少遍历链表的次数，提高效率

至于如何分配tickets，这是一个开放问题，用户可以根据需求自定义每个进程的tickets数量
在进程间友好的环境下可以让进程自己产生更多的tickets，但是如果进程间存在竞争的话，进程就会不断产生新的tickets，从而导致诸多问题
此外用户也可以根据需求给指定的进程更多票据，来优先完成某些任务之类的
系统自行分配tickets可以参照之前的OS调度的思路，执行时间越久的进程分配的票据越少，每进行一段时间就从其tickets中拿走一些

## Stride Scheduling
使用Lottery Scheduling的问题在于，当某个进程分配的tickets很少时，有可能会导致其一直都无法被调度执行，使得这个进程进入饥饿状态

所以这里书上再介绍了一种方式：Stride Scheduling（步幅调度）

我们用与Lottery Scheduling相似的方式给每个进程分配一个stride（步幅）和一个pass（经过长度），其中stride和其tickets数量成反比

然后初始状态所有进程的pass都为0，我们随机从中选择进程调度执行一个time quantum，然后将其pass值加上stride，然后再从pass值最小的进程中选择一个调度运行，以此类推

这样我们就能保证每个步幅的进程都能得到相应概率的调度运行

但是Stride Scheduling并不支持global state（全局状态），也就是说，我们只能对几个固定的进程进行Stride Scheduling，而不能对全部进程进行，如果此时有一个新的进程需要加入调度列表，其他的进程的pass值已经很大，新进程的pass值如果只是0的话，那么新进程就会占据CPU的使用，这样就会导致其他进程饥饿

虽然书上没有进一步说明，但是我认为pass值是可以根据现有的进程的pass值预估出一个合理的值的

## CFS（Completely Fair Scheduler）

CFS是Linux使用的进程调度方式，这个调度法的主要参数有两个：
- vruntime（虚拟运行时间）
- sched_latency（调度延迟）

vruntime并不是进程实际运行的时间，而是CFS评估进程是否调度的一个标准，是基于优先级和实际运行时间计算出的一个数值

sched_latency作为调度延迟，实际意义指一个进程在运行完自己的min_time后，再次被调度执行之前，需要等待的时间
用另一种方式来思考的话，我们可以先假设进程运行的时间被sched_latency所分，也就是说每个区间的长度为sched_latency，然后在这个区间中每个进程需要平分这段时间，也就是说每个进程的time slice为sched_latency / 进程数(n)

这样的话就能保证每个进程被调用的平均延迟（latency）为sched_latency，同时为了防止同时进行的进程过多，导致每个进程的min_time过短，导致context switching产生overhead，所以对于sched_latency划分的值会设定一个min_granluarity（最小粒度），这也就导致当进程数过多时，进程之间必然不能完全公平，有些进程将得不到调度运行

大概对这两个参数有个了解之后我们通过一个例子来说明CFS的运作方式：

现在假设有4个进程A、B、C、D，他们的初始vruntime都为0，sched_latency为1000，min_granularity为100，那么我们可以得到每个进程的min_time为1000 / 4 = 250，也就是说每个进程在一个sched_latency的时间内至少要运行250的时间才能被中断

- tips：min_time并不一定是time quantum的倍数，我们以time quantum进行累加，超过了min_time就认定为完成了应该运行的时间

一个进程运行会累加他的vruntime，当vruntime大于250时CFS就会去寻找一个vruntime小于250的进程来运行

这样相同优先级的进程就能平分cpu的占用时间

但是我们之前说了**vruntime**是通过公式计算出来的一个虚拟的运行时间，对于一个优先级高的进程，它运行的实际时间应该要更多一些，但是我们不能去修改由sched_latency均分而来的time slice（这样就破坏了CFS公平的部分），所以我们的vruntime的累加是由公式来计算的，公式如下：
$$vruntime_i = vruntime_i + \frac{weight_0}{weight_i}\times runtime_i$$

这里的$weight$指的是优先级的权重，$weight_0$是标准优先级的权重，不同优先级的权重由下所示：

```c
static const int prio_to_weight[40] = {
/* -20 */ 88761, 71755, 56483, 46273, 36291,
/* -15 */ 29154, 23254, 18705, 14949, 11916,
/* -10 */ 9548, 7620, 6100, 4904, 3906,
/* -5 */ 3121, 2501, 1991, 1586, 1277,
/* 0 */ 1024, 820, 655, 526, 423,
/* 5 */ 335, 272, 215, 172, 137,
/* 10 */ 110, 87, 70, 56, 45,
/* 15 */ 36, 29, 23, 18, 15,
};
```
这是书上所示的优先级及其对应的权重，负数的优先级代表高优先，正数代表低优先

通过以上的优先级权重表就可以计算对应的vruntime的累加了
相应的，也可以通过其权重和sched_latency计算出每个进程的实际运行的时间

## 使用红黑树

为了能够快速找到正在运行的进程中的vruntime最小的进程，我们需要使用适合的数据结构来储存这些进程的信息

Linux使用了红黑树来完成这个工作，并且带有对最小值的缓存，所以有相当概率可以在O(1)的时间内找到最小值，即便缓存不命中，也只需要O(logn)的时间
而完成运行后的进程需要重新加入红黑树中，仍然只需要O(logn)的时间即可

关于红黑树的文章如下：
https://dnullp.github.io/2023/01/25/data_struct/RBTree/

## 关于长时间休眠的进程
长时间休眠的进程重新开始运行后，其vruntime会远小于其他进程，从而导致其独占CPU的使用，所以我们要对其vruntime进行调整，Linux会选择红黑树中最小的进程，设置为其新的vruntime，这样能够避免进程的饥饿状态，但是一定程度上破坏了公平性



    </span>

  </div>

</div>



  
  
  

<div class="card" style="justify-content: left;">

  <div class="card-content">

    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        2.7k字
      </div>
      <div class="card-info">
        阅读时间: 2 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <div style="transform: translateX(10px);">
      <a class="card-title" href="/2021/01/01/operating-system/leading-chapter/">
        Operating System Chapter 1
      </a>
      <span class="card-abstract" style="transform: translateX(0px);">
        
The document I am learning is *Operating Systems: Three Easy Pieces*, and there is the address https://pages.cs.wisc.edu/~remzi/OSTEP/.

This is a online free ebook, and someone recommended it to me.

I will take down the note and what I thought here, and this is only the record of my learning, so don&#39;t consider it as an authenticated tutorial. However, if I make some mistake, I will be glad you can point out for me.

&#34;three Pieces&#34; of the book is *virtualize*, *concurrency* and *persistence*, which are also the importance of each chapter.

Here are several key points below it reveals in the preface: 
- What the first of each chapter describes is crux of the problem.
- The timelines shown in the book will be of essence to understand the principle of the device
- **Asides** is the relevant but not essential, and **tips** can be used in your system
- There is homework sprinkled in the text
- All the example code is written in C (which I am familiar with)

---

## 冯诺依曼计算机架构

intro篇通过冯诺依曼机引入操作系统

冯诺依曼结构我们在CSAPP中有所了解：
即计算机对于每条指令执行：
- 取指
- 译码
- 执行
（完善之后还有访存和写回阶段）
现在绝大多数计算机都遵循这个架构的设计，但是实际上在每条指令运行的同时，还有很多其他的程序在运行着，目的是为了让计算机变得更容易使用

试想一下只有这三个操作的计算机，你编写程序时需要先写读取内存的指令，然后如果没有得到结果又要从硬盘中读取指令，然后把指令写入内存，然后......

OS便是因此诞生的程序，通过将硬件虚拟化，映射到程序中，使得在操作系统之上编写的程序可以简单完成内存管理、并发运行、硬件交互等等

所有的这些内存、硬件我们都可以看作OS的资源，所以OS又叫做资源管理器（resource manager）

## CPU虚拟化
我们只有一个CPU，但是程序却可以同时运行，这是由操作系统实现的一种假象，实际上CPU在不同程序之间切换来造成一种同时运行程序的假象，这是CPU虚拟化的一个表现

实际上现代CPU有多个核心，计算机确实可以使用多个核心来真正意义上地实现多线程程序

## 内存虚拟化
每个程序的内存空间和分开的各自的内存空间，我们称为虚拟内存，这些内存地址实际上是随机映射到物理内存上的，所有程序共用一个物理内存，但是OS管理物理内存，并把其分成若干虚拟内存分给各个应用程序使用

## 并发运行
这个主要涉及到多线程部分
这里不得不提一下 **并发（concurrent）** 和 **并行（parallel）** 的区别，并发是指OS同时管理一个程序的很多部分，我们可以编写一个多线程程序，然后OS会根据情况切换CPU的上下文，执行不同的线程，造成计算机同时运行多个线程的假象，实际上只是线程交替运行，这叫并发

而当我们的CPU有多个处理核心时，OS就会把线程分配到不同的核心上计算，这时才真正实现了多个线程同时进行，这叫并发

并发可以有效利用有限的计算机资源，比如当一个线程需要向磁盘读取一段数据时，CPU便切换上下文到另一个线程计算，等到磁盘读取完毕后，向OS发送信号，然后再切换回原来的线程继续计算，这样就有效利用了CPU处理的各种空档时间
而并行运算则是利用更多的计算核心协同工作，来提高计算效率

## 持久性

内存保存数据是不稳定的，当电源切断后，内存中的数据就消失了，所以为了实现持久性，我们将硬件作为I/O设备的形式出现，然后通过磁盘、SSD等I/O设备来完成数据的持久储存

后面还会讨论更多细节，比如当读写硬盘遇到问题如何反馈，文件系统的数据结构如何高效，如何访问查找数据等等

## OS的设计目标

- 实现硬件设施的抽象
- 高性能、节约能源
- 进程安全且独立
- OS必须持久可靠

## OS的发展历程
最开始，OS只是一系列的标准库，用户可以通过这些标准库来对硬件进行操作，并且这些程序被交给计算机操作员排队批处理（那时候计算机不普及，费用高，使用需要申请使用，类比现在超算）

但是使用标准库来操作硬件的级别过低，使得用户可以随意更改全部硬件，容易造成错误的访问，所以最初的操作系统引入了一个权限模式，操作系统分为用户模式和内核模式，用户模式可以访问允许的硬件，用户调用系统调用后，操作系统触发中断（trap），进入内核模式，完成系统调用后返回用户模式，再切换回原本的程序运行
这是最开始引入的操作系统的安全性

然后小型计算机出现，多进程成为了操作系统发展的主要方向，人们希望计算机能够同时进行多个程序的运行，所以内存的保护和中断后上下文的切换等功能的实现成为了当时的主要挑战
这些工作后来由UNIX系统完成并沿用至今日

之后就是现代操作系统的诞生，不再多讲述

      </span>
    </div>
  </div>

  <div class="card-img">
    <div class="img-container"></div>
  </div>

</div>



  
  
  
<div class="card" style="justify-content: right;">

  <div class="card-img">
    <div class="img-container"></div>
  </div>

  <div class="card-content">
    <div class="card-info-warp">
      <div class="card-info">
        2021-01-01
      </div>
      <div class="card-info">
        1.4k字
      </div>
      <div class="card-info">
        阅读时间: 1 mins.
      </div>
    </div>
    <div style="display: flex;">
      <svg xmlns="http://www.w3.org/2000/svg" width="392" height="2" viewBox="0 0 392 2" fill="none">
        <path d="M0 1L392 1.00003" stroke="#A5BFF2" />
      </svg>
    </div>
    <a class="card-title" href="/2021/01/01/network/works-projects/wireShark-1-inro/">
      wireshark practice 1
    </a>
    <span class="card-abstract">
      
计网开课了, 复习一下遗忘的东西, 顺便做一下课本后的wireshark实验

# lab1: intro to wireshark

1. List 3 different protocols that appear in the protocol column in the unfiltered packet-listing window in step 7 above.  

- DNS
- TCP
- UDP
- TLSv1.2
- SSDP
- ICMPv6

---

2. How long did it take from when the HTTP GET message was sent until the HTTP OK reply was received? (By default, the value of the Time column in the packet-listing window is the amount of time, in seconds, since Wireshark tracing began.  To display the Time field in time-of-day format, select the Wireshark View pull down menu, then select Time Display Format, then select Time-of-day.)

|419|13:34:02.688933|10.122.242.69|128.119.245.12|
|-|-|-|-|
|447| 13:34:03.015422| 128.119.245.12| 10.122.242.69|
以上为发送`GET`和接收数据帧的数据
可计算出时间差为`0.326489`秒

---

3. What is the Internet address of the gaia.cs.umass.edu (also known as www-net.cs.umass.edu)?  What is the Internet address of your computer?

`10.122.242.69`这是我的IP地址(北京邮电大学的, 别查了)
`128.119.245.12`这是服务器地址

---
4. Print the two HTTP messages (GET and OK) referred to in question 2 above. To do so, select Print from the Wireshark File command menu, and select the “Selected Packet Only” and “Print as displayed” radial buttons, and then click OK.

打印文件如下:
[print_1](/pdf/wireshark1.pdf)


    </span>

  </div>

</div>



  
</div>



<div id="paginator">
  <a class="extend prev" rel="prev" href="/page/12/">Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="page-number" href="/page/12/">12</a><span class="page-number current">13</span><a class="page-number" href="/page/14/">14</a><a class="page-number" href="/page/15/">15</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/14/">Next</a>
</div>
    </div>

  </div>



  
  <!-- scripts list from theme config.yml -->
  
  <script src="/js/layout/animation.js"></script>
  
  <script src="/js/layout/svg.js"></script>
  
  <script src="/js/csstool.js"></script>
  
  

</body>

</html>