import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as t,c as n,e as a}from"./app-DCTCPPGQ.js";const o={},l=a('<h2 id="依然还是关键词的记录" tabindex="-1"><a class="header-anchor" href="#依然还是关键词的记录"><span>依然还是关键词的记录</span></a></h2><h3 id="lexeme-token-pattern" tabindex="-1"><a class="header-anchor" href="#lexeme-token-pattern"><span>Lexeme, Token, Pattern</span></a></h3><ul><li>Token: &lt;id, &quot;a&quot;&gt; &lt;num, 10&gt; 像这样已经完成解析, 包含了若干属性的单元我们称为Token</li><li>Pattern: 模式, 用来匹配一个串的, 比较常见的匹配包括了正则匹配</li><li>Lexeme: 最小的语句单元, 我们可以认为一个模式所能匹配的最小单元为一个Lexeme(词素) <code>int a = 10</code></li></ul><p>在这里面, <code>int</code> <code>a</code> <code>=</code> <code>10</code> 都是词素, 匹配了每一个词素的规则(一般是正则表达式)称为模式, 模式匹配的结果<code>&lt;id, &#39;a&#39;&gt;</code>称为Token</p><h3 id="concatenation-exponentiation" tabindex="-1"><a class="header-anchor" href="#concatenation-exponentiation"><span>concatenation, exponentiation</span></a></h3><ul><li>concatenation 连接, 例如<code>ab</code>表示<code>a</code>和<code>b</code>的concatenation</li><li>exponentiation 幂, 例如<code>a^3 = aaa</code>表示<code>a</code>的0次或多次concatenation</li></ul><h3 id="kmp和dfa" tabindex="-1"><a class="header-anchor" href="#kmp和dfa"><span>KMP和DFA</span></a></h3><p>又见到KMP了, 回头再简单集记篇随笔说说kmp和DFA</p><h3 id="nfa-dfa-regular-expression" tabindex="-1"><a class="header-anchor" href="#nfa-dfa-regular-expression"><span>NFA, DFA, Regular Expression</span></a></h3><p>这部分记自动机内了</p><h3 id="regular-definition" tabindex="-1"><a class="header-anchor" href="#regular-definition"><span>Regular Definition</span></a></h3><p>正则定义是一些正则表达式定义的变量, 用以组成complex language, 比如: <code>digit = [0-9]</code>, <code>letter = [a-zA-Z]</code>都是正则定义</p><h3 id="flex" tabindex="-1"><a class="header-anchor" href="#flex"><span>Flex</span></a></h3><p>Flex是一个词法分析器生成器, 用来生成词法分析器, 词法分析器的输入是一个正则表达式, 输出是一个DFA, 用来匹配输入的字符串, 词法分析器的输出是一个Token序列</p><ul><li>flex中的正则表达式按照最长优先匹配</li><li>按照编写的顺序优先匹配</li></ul><h3 id="two-buffers" tabindex="-1"><a class="header-anchor" href="#two-buffers"><span>two buffers</span></a></h3><p>缓冲区是必要的, 对于大型源码一次性读完浪费, 从磁盘读取又太慢, 但是使用缓冲区必然产生断层, 所以使用两个缓冲区来交替连接</p><p>当读到一个缓冲区的结尾时, 将另一个缓冲区进行刷新, 然后读取头移动到另一个缓冲区即可</p><p>一般我们编写代码时要避免缓冲区溢出, 比如对于一个超长的字符串, 我们应该拆分为String的concatenation形式</p><h3 id="lexemepos-forward" tabindex="-1"><a class="header-anchor" href="#lexemepos-forward"><span>lexemepos, forward</span></a></h3><p>lexemepos记录词素的开始位置, forward向后读若干位, 直到到达一个无法转移的状态, 然后再之前的匹配中寻找满足要求的匹配</p><hr><h2 id="记几个概念点" tabindex="-1"><a class="header-anchor" href="#记几个概念点"><span>记几个概念点:</span></a></h2><h3 id="词法分析器生成器的架构" tabindex="-1"><a class="header-anchor" href="#词法分析器生成器的架构"><span>词法分析器生成器的架构</span></a></h3><p>flex读取了lex源码后, 会生成对应的词法分析器, 而词法分析器本身是个状态机, 我们可以选择用NFA和DFA来生成这个分析器, 不过一般会选用DFA, 其状态转移更简明</p>',25),i=[l];function r(c,d){return t(),n("div",null,i)}const h=e(o,[["render",r],["__file","CH3-note.html.vue"]]),m=JSON.parse(`{"path":"/posts/CS/compiler/CH3-note.html","title":"编译原理-词法解析","lang":"zh-CN","frontmatter":{"title":"编译原理-词法解析","tags":["compiler","词法分析","语法分析","语义分析","中间代码生成"],"categories":["compiler"],"math":true,"date":"2023-04-25T00:00:00.000Z","description":"依然还是关键词的记录 Lexeme, Token, Pattern Token: <id, \\"a\\"> <num, 10> 像这样已经完成解析, 包含了若干属性的单元我们称为Token Pattern: 模式, 用来匹配一个串的, 比较常见的匹配包括了正则匹配 Lexeme: 最小的语句单元, 我们可以认为一个模式所能匹配的最小单元为一个Lexeme(词...","head":[["meta",{"property":"og:url","content":"https://Dnullp.github.io/posts/CS/compiler/CH3-note.html"}],["meta",{"property":"og:site_name","content":"Dnull's Blog"}],["meta",{"property":"og:title","content":"编译原理-词法解析"}],["meta",{"property":"og:description","content":"依然还是关键词的记录 Lexeme, Token, Pattern Token: <id, \\"a\\"> <num, 10> 像这样已经完成解析, 包含了若干属性的单元我们称为Token Pattern: 模式, 用来匹配一个串的, 比较常见的匹配包括了正则匹配 Lexeme: 最小的语句单元, 我们可以认为一个模式所能匹配的最小单元为一个Lexeme(词..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"Dnull"}],["meta",{"property":"article:tag","content":"compiler"}],["meta",{"property":"article:tag","content":"词法分析"}],["meta",{"property":"article:tag","content":"语法分析"}],["meta",{"property":"article:tag","content":"语义分析"}],["meta",{"property":"article:tag","content":"中间代码生成"}],["meta",{"property":"article:published_time","content":"2023-04-25T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"编译原理-词法解析\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-04-25T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Dnull\\",\\"url\\":\\"https://Dnullp.github.io\\"}]}"]]},"headers":[{"level":2,"title":"依然还是关键词的记录","slug":"依然还是关键词的记录","link":"#依然还是关键词的记录","children":[{"level":3,"title":"Lexeme, Token, Pattern","slug":"lexeme-token-pattern","link":"#lexeme-token-pattern","children":[]},{"level":3,"title":"concatenation, exponentiation","slug":"concatenation-exponentiation","link":"#concatenation-exponentiation","children":[]},{"level":3,"title":"KMP和DFA","slug":"kmp和dfa","link":"#kmp和dfa","children":[]},{"level":3,"title":"NFA, DFA, Regular Expression","slug":"nfa-dfa-regular-expression","link":"#nfa-dfa-regular-expression","children":[]},{"level":3,"title":"Regular Definition","slug":"regular-definition","link":"#regular-definition","children":[]},{"level":3,"title":"Flex","slug":"flex","link":"#flex","children":[]},{"level":3,"title":"two buffers","slug":"two-buffers","link":"#two-buffers","children":[]},{"level":3,"title":"lexemepos, forward","slug":"lexemepos-forward","link":"#lexemepos-forward","children":[]}]},{"level":2,"title":"记几个概念点:","slug":"记几个概念点","link":"#记几个概念点","children":[{"level":3,"title":"词法分析器生成器的架构","slug":"词法分析器生成器的架构","link":"#词法分析器生成器的架构","children":[]}]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":2.2,"words":659},"filePathRelative":"posts/CS/compiler/CH3-note.md","localizedDate":"2023年4月25日","excerpt":"<h2>依然还是关键词的记录</h2>\\n<h3>Lexeme, Token, Pattern</h3>\\n<ul>\\n<li>Token:\\n&lt;id, \\"a\\"&gt;\\n&lt;num, 10&gt;\\n像这样已经完成解析, 包含了若干属性的单元我们称为Token</li>\\n<li>Pattern:\\n模式, 用来匹配一个串的, 比较常见的匹配包括了正则匹配</li>\\n<li>Lexeme:\\n最小的语句单元, 我们可以认为一个模式所能匹配的最小单元为一个Lexeme(词素)\\n<code>int a = 10</code></li>\\n</ul>\\n<p>在这里面, <code>int</code> <code>a</code> <code>=</code> <code>10</code> 都是词素, 匹配了每一个词素的规则(一般是正则表达式)称为模式, 模式匹配的结果<code>&lt;id, 'a'&gt;</code>称为Token</p>","autoDesc":true}`);export{h as comp,m as data};
